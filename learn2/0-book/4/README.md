# 四、机器学习基础
-
* 人工智能 > **机器学习** > 深度学习 > 神经网络

## 4.1 机器学习的四个分支
### 1.监督学习
	找到训练输入与训练输出之间的关系
监督学习主要包括：分类问题、回归问题，还有更多的变体，主要包括：

* 序列生成（sequence generation 顺序一代）:给定一张图像，预测描述图像的文字。序列生成有时 可以被重新表示为一系列分类问题，比如反复预测序列中的单词或标记。？
* 语法树预测（syntax tree prediction 语法树预测）给定一个句子，预测其分解生成的语法树。<b>何为语法树？</b>
* 目标检测（object detection 对象发现）：给定一张图像，在图中特定目标的周围画一个边界框。这 个问题也可以表示为分类问题(给定多个候选边界框，对每个框内的目标进行分类)或分类与回归联合问题(用向量回归来预测边界框的坐标)
* 图像分割（image segmentation 图像分割）：给定一张图像，在特定物体上画一个像素级的掩模（mask）

### 2.无监督学习
	在没有目标（可能指损失函数）的情况下找到输入数据的有趣变换，其目的在于数据可视化、数据压缩、数据去噪或更好地理解数据中的相关性
* 降维（dimensionality reduction）
* 聚类（clustering）

### 3.自监督学习
	监督学习的一个特例：没有人工标注的标签的监督学习
* 标签依然存在（因为总要有什么东西来监督学习过程），但它们是从输入数据中生成的，通常是使用启发式算法生成的。
* 举个例子，自编码器(autoencoder)是有名的自监督学习的例子，其生成的目标就是未经 修改的输入。同样，给定视频中过去的帧来预测下一帧，或者给定文本中前面的词来预测下一个词， 都是自监督学习的例子[这两个例子也属于时序监督学习(temporally supervised learning)，即用 6 未来的输入数据作为监督]。注意，监督学习、自监督学习和无监督学习之间的区别有时很模糊， 这三个类别更像是没有明确界限的连续体。自监督学习可以被重新解释为监督学习或无监督学 习，这取决于你关注的是学习机制还是应用场 。

### 4.强化学习
智能体(agent)接收有关其环境的信息，并学会选择使某种奖励最大化的 **行动**
> 自我理解：监督学习是找出训练输入与训练输出之间的关系，而强化学习是接收信息，然后学会做出选择某行动，使某种奖励最大化

## 4.2 评估机器学习模型
	如何衡量模型的泛化能力
	
### 1. 训练集、验证集、测试集
将数据分为三个集合，训练集、验证集、测试集，而不是两个集合训练集和测试集。这样做主要原因在于，在训练集上训练模型，在开发时总需要调节模型超参数，这个调节过程需要使用模型在第二个集合上的性能作为反馈信号📶，这就导致第二个集合的信息会泄漏到模型中，模型在第二个集合上就过拟合，即使你**并没有直接**在第二个集合上训练模型也是如此，所以需要第三个集合（前所未见的数据集合）来做测试，评估模型的泛化能力

* 训练集：训练模型
* 验证集：评估模型，并做出调整
* 测试集：测试模型

* 划分集合的方法：
	1. 简单的留出验证集
	2. K折验证
	3. 带有打乱数据的重复K折验证

### 2. 评估模型的注意⚠️事项
* 数据代表性（data representativeness）
* 时间箭头➡️（the arrow of time）
* 数据冗余（redundancy in your data）


## 4.3 数据预处理、特征工程和特征学习
	将数据输入神经网络之前，如何准备输入数据和目标？


## 4.4 过拟合和欠拟合


## 4.5 机器学习的通用工作流
