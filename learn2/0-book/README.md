# 三、神经网络入门
## 3.1 神经网络剖析
* <b>层</b>，多个层组合成<b>网络</b>（或<b>模型</b>）
* <b>输入数据</b>和对应的<b>目标</b>
* <b>损失函数</b>：训练过程中需要将其最小化
* <b>优化器</b>：决定如何基于损失函数对网络进行更新，它的执行是随机梯度下降（<b>SGD</b>）的某个变体
* <b>衡量标尺</b>：

## 3.5.9 小结（page=66）
下面是你应该从[这个例子](https://github.com/CLgithub/tensorFlowLearn/blob/master/learn2/0-book/book3.5.py)中学到的要点：

* 如果要对N个类别的数据点进行分类，网络的最后一层应该是大小为N的Dense层。
* 对于单标签、多分类问题，网络的最后一层应该使用softmax激活函数，这样可以输出在N个输出类别上的概率分布。
* 这种问题的损失函数几乎总是应该使用分类交叉熵。它将网络输出的概率分布与目标的真是分布之间的距离最小化。
* 处理多分类问题的标签有两种方法：
	* 通过分类编码（也叫one-hot编码）对标签进行编码，然后使用categorical\_crossentropy作为损失函数。
	* 将标签编码为整数，然后使用sparse\_categorical\_crossentropy损失函数。
* 如果你需要将数据划分到许多分类中，应该避免使用太小的中间层，以免在网络中造成信息瓶颈。