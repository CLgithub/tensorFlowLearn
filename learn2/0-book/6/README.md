# 六、深度学习用于文本和序列
--
本章包括以下内容：

* 将文本数据处理为有用的数据表示
* 使用循环神经网络
* 使用一维卷积神经网络处理序列

本章将介绍使用深度学习模型处理**文本序列**、**时间序列**、**一般序列**数据<br>
用于处理序列的两种基本的深度学习算法：

* 循环神经网络（recurrent neural network）
* 一维卷积神经网络（1D convnet）（已经大概能想到）

主要应用：

* 文本分类和时间序列分类，比如识别文章的主题或书的作者
* 时间序列对比，比如估测两个文档或两支股票行情的相关程度
* 序列到序列的学习，比如将英语翻译成法语
* 情感分析，比如将推文或电影评论的情感划分为正面或负面
* 时间序列预测，比如根据某地最近的天气数据来预测未来天气

## 6.1 处理文本数据
**深度学习用于自然语言处理是将模式识别应用于单词、句子和段落，这与计算机视觉是将模式识别应用于像素大致相同**<br>

文本向量化(vectorize)是指将文本转换为数值张量的过程。它有多种实现方法：

* 将文本分割为单词，并将每个单词转换为一个向量（1D张量）
* 将文本分割为字符，并将每个字符转换为一个向量
* 提取单词或字符的n-gram，并将每个n-gram转换为一个向量。n-gram是多个连续单词或字符的集合（词袋）

**标记(token)**：将文本分解而成的单元（单词、字符、g-gram）<br>
**分词(tokenization)**：将文本分解成标记的过程<br>
**文本向量化**：文本--*(分词)*-->标记-->*(关联)*-->数值向量
![](./images/6.1-1.png)

分词方法有很多，关联方法也有很多，两种主要**关联方法**：

* one-hot编码(one-hotencoding)
* 标记嵌入[token embedding,通常只用于单词，叫作**词嵌入(word embedding)**]

### 6.1.1 单词和字符的one-hot编码
每个单词与一个唯一的整数索引相关联，如果将这个整数索引 i 转换为长度为N的二进制向量（N是词表大小），这个向量只有第i个元素是1，其余元素都为0

### 6.1.2 使用词嵌入
### 6.1.3 整合在一起:从原始文本到词嵌入
### 6.1.4 小结

## 6.2 理解循环神经网络

### 6.2.1 Keras 中的循环层
### 6.2.2 理解 LSTM 层和 GRU 层
### 6.2.3 Keras 中一个 LSTM 的具体例子
### 6.2.4 小结

## 6.3 循环神经网络的高级用法
### 6.3.1 温度预测问题
### 6.3.2 准备数据
### 6.3.3 一种基于常识的、非机器学习的基准方法
### 6.3.4 一种基本的机器学习方法
### 6.3.5 第一个循环网络基准
### 6.3.6 使用循环dropout来降低过拟合
### 6.3.7 循环层堆叠
### 6.3.8 使用双向RNN
### 6.3.9 更多尝试
### 6.3.10 小结

## 6.4 用卷积神经网络处理序列
### 6.4.1 理解序列数据的一维卷积
### 6.4.2 序列数据的一维池化
### 6.4.3 实现一维卷积神经网络
### 6.4.4 结合CNN和RNN来处理长序列
### 6.4.5 小结

## 本章总结

