#coding=utf-8

# çŒ«ğŸ± ç‹—ğŸ¶ å›¾ç‰‡åˆ†ç±»å™¨

import os, shutil
from keras import layers
from keras import models
from keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt

original_dataset_dir='/Users/l/develop/clProject/tensorFlowLearn/learn2/0-book/5/data/dogs-vs-cats/train'   #åŸå§‹æ•°æ®é›†è§£å‹ç›®å½•çš„è·¯å¾„
base_dir='/Users/l/develop/clProject/tensorFlowLearn/learn2/0-book/5/data/cats_and_dogs_small'  #ä¿å­˜è¾ƒå°æ•°æ®é›†çš„ç›®å½•
#os.mkdir(base_dir)
train_dir=os.path.join(base_dir, 'train')   #è®­ç»ƒ
validation_dir=os.path.join(base_dir, 'validation') #æ ¡éªŒ
test_dir=os.path.join(base_dir, 'test') #æµ‹è¯•
train_cats_dir=os.path.join(train_dir, 'cats')
train_dogs_dir=os.path.join(train_dir, 'dogs')
validation_cats_dir=os.path.join(validation_dir, 'cats')
validation_dogs_dir=os.path.join(validation_dir, 'dogs')
test_cats_dir=os.path.join(test_dir, 'cats')
test_dogs_dir=os.path.join(test_dir, 'dogs')

# å‡†å¤‡æ•°æ®
def copyData():
    #å°†å‰1000å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°train_cats_dir
    fnames=['cat.{}.jpg'.format(i) for i in range(1000)]  #{}æ˜¯å ä½ç¬¦ï¼Œå¡«å†™format(i)ä¸­çš„i å¾—åˆ°cat.0.jpg,cat.1.jpg...
    for fname in fnames:
        src = os.path.join(original_dataset_dir, fname)
        dst = os.path.join(train_cats_dir, fname)
        shutil.copyfile(src, dst)
    #å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°validation_cats_dir
    fnames=['cat.{}.jpg'.format(i) for i in range(1000,1500)]
    for fname in fnames:
        src = os.path.join(original_dataset_dir, fname)
        dst = os.path.join(validation_cats_dir, fname)
        shutil.copyfile(src, dst)
    #å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°test_cats_dir
    fnames=['cat.{}.jpg'.format(i) for i in range(1500,2000)]
    for fname in fnames:
        src = os.path.join(original_dataset_dir, fname)
        dst = os.path.join(test_cats_dir, fname)
        shutil.copyfile(src, dst)

    fnames=['dog.{}.jpg'.format(i) for i in range(1000)]
    for fname in fnames:
        src = os.path.join(original_dataset_dir, fname)
        dst = os.path.join(train_dogs_dir, fname)
        shutil.copyfile(src, dst)
    #å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°validation_cats_dir
    fnames=['dog.{}.jpg'.format(i) for i in range(1000,1500)]
    for fname in fnames:
        src = os.path.join(original_dataset_dir, fname)
        dst = os.path.join(validation_dogs_dir, fname)
        shutil.copyfile(src, dst)
    #å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°test_cats_dir
    fnames=['dog.{}.jpg'.format(i) for i in range(1500,2000)]
    for fname in fnames:
        src = os.path.join(original_dataset_dir, fname)
        dst = os.path.join(test_dogs_dir, fname)
        shutil.copyfile(src, dst)

#copyData()

#æ­å»ºæ¨¡å‹
model=models.Sequential()
model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))
model.add(layers.MaxPooling2D(2,2))
model.add(layers.Conv2D(64, (3,3), activation='relu' ))
model.add(layers.MaxPooling2D(2,2))
model.add(layers.Conv2D(128, (3,3), activation='relu' ))
model.add(layers.MaxPooling2D(2,2))
model.add(layers.Conv2D(128, (3,3), activation='relu' ))
model.add(layers.MaxPooling2D(2,2))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
print(model.summary())
# ç¼–è¯‘æ¨¡å‹
model.compile(loss='binary_crossentropy',
            optimizer=optimizers.RMSprop(lr=1e-4),
            metrics=['acc']
        )

#æ•°æ®é¢„å¤„ç†
train_datagen=ImageDataGenerator(rescale=1./255)    #è®¾ç½®æ”¾ç¼©æ¯”ä¾‹
test_datagen=ImageDataGenerator(rescale=1./255)

train_generator=train_datagen.flow_from_directory(  #æ„å»ºpythonç”Ÿæˆå™¨,æ˜¯ä¸€ä¸ªç±»ä¼¼è¿­ä»£å™¨çš„å¯¹è±¡,ä»ç›®å½•ä¸­è¯»å–å›¾åƒæ•°æ®å¹¶é¢„å¤„ç†
    train_dir,  #ç›®æ ‡ç›®å½•
    target_size=(150, 150), #å°†æ‰€æœ‰å›¾ç‰‡çš„å¤§å°è°ƒæ•´ä¸º150*150
    batch_size=20,          #ç”Ÿæˆå™¨æ¯æ‰¹æ¬¡æ ·æœ¬æ•°é‡
    class_mode='binary'     #å› ä¸ºä½¿ç”¨äº†binary_crossentropyæŸå¤±ï¼Œæ‰€ä»¥éœ€è¦ç”¨äºŒè¿›åˆ¶æ ‡ç­¾
    )
validation_generator=test_datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary'
    )

history=model.fit_generator(    #å¼€å§‹è®­ç»ƒï¼Œfit_generatoråœ¨æ•°æ®ç”Ÿæˆå™¨ä¸Šçš„æ•ˆæœå’Œfitç›¸åŒ
    train_generator,      #æ•°æ®ç”Ÿæˆå™¨,å¯ä»¥ä¸åœçš„ç”Ÿæˆè¾“å…¥å’Œç›®æ ‡ç»„æˆçš„æ‰¹é‡
    steps_per_epoch=100,    # æ¯ä¸€è½®æŠ½å–å¤šå°‘æ‰¹æ¬¡çš„ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®ï¼Œæœ¬ä¾‹ä¸­ï¼Œæ¯æ‰¹é‡20ï¼Œå…±2000ï¼Œæ‰€ä»¥æ¯è½®æŠ½å–100ä¸ªæ‰¹æ¬¡æ•°æ®ç”Ÿæˆå™¨çš„æ•°æ®ï¼Œè½®è®­å®Œä¸€è½®ç”¨å®Œæ‰€æœ‰å›¾ç‰‡
    epochs=10,              # è½®è®­æ¬¡æ•°
    validation_data=validation_generator,   #éªŒè¯é›†ï¼Œå¯ä»¥æ˜¯numpyï¼Œä¹Ÿå¯ä»¥æ˜¯æ•°æ®ç”Ÿæˆå™¨
    validation_steps=50                 # ä»éªŒè¯é›†ä¸­æŠ½å–å¤šå°‘ä¸ªæ‰¹æ¬¡ç”¨äºè¯„ä¼°
    )

model.save('cats_and_dogs_small_1.h5')  #ä¿å­˜æ¨¡å‹

def show2(t_loss,t_acc,v_loss,v_acc):
    epochs=range(1, len(t_loss)+1)
    plt.figure(figsize=(10,5))
    plt.subplot(1,2,1)
    plt.plot(epochs, t_loss, 'b', label='t_loss')
    plt.plot(epochs, v_loss, 'r', label='v_loss')
    plt.ylim([0,2])
    plt.title('loss')
    plt.legend()
    plt.subplot(1,2,2)
    plt.plot(epochs, t_acc, 'b', label='t_acc')
    plt.plot(epochs, v_acc, 'r', label='v_acc')
    plt.ylim([0,1])
    plt.title('acc')
    plt.legend()
    plt.show()

t_loss=history.history['loss']
t_acc=history.history['acc']
v_loss=history.history['val_loss']
v_acc=history.history['val_acc']

show2(t_loss,t_acc,v_loss,v_acc)
