# 八、生成式深度学习
本章包括以下内容:

* 使用LSTM生成文本
* 使用DeepDream
* 使用神经风格迁移
* 变分自编码
* 了解生成式对抗网络

机器学习模型能够对图像、音乐和故事的统计**潜在空间(latent space)**进行学习，然后从这个空间中**采样(sample)**，创造出与模型在训练数据中所见到的艺术作品具有相似特征的新作品。

它从一种与我们的经验完全不同的经验中进行学习

作为人类旁观者，只能靠我们的解释才能对模型生成的内容赋予意义。

👻：生成的内容本身没有什么意义，人类的解释才能对内容赋予意义

👻：和自监督学习有何关系

## 8.1 使用LSTM生成文本
本节将会探讨如何将循环神经网络用于生成序列数据
### 8.1.1 生成式循环网络简史
2013年Alex Graves 利用笔触位置的时间序列将循环混合密度网络应用于生成 类似人类的手写笔迹，有人认为这是一个转折点。

“序列数据生成是计算机所做的最接近于做梦的事情。”

从那以后，循环神经网络已被成功应用于音乐生成、对话生成、图像生成、语音合成和分 子设计。它甚至还被用于制作电影剧本，然后由真人演员来表演。

### 8.1.2 如何生成序列数据
通用方法：使用前面的标记 作为 **输入**，训练一个网络，来**预测**序列中接下来的**一个或多个标记**<br>
例如：给定输入 “the cat is on the ma”，训练网络来预测下一个字符 "t"

**语言模型(language model)**：给定标记，能够对下一个标记的概率进行建模的任何网络

**潜在空间(latent space)**：语言的统计结构

**整体流程**：向模型中输入一个初始文本字符串，要求模型生成下一个字符或下一个或多个单词，然后将生成的输出添加到输入数据中，多重重复这一过程
<center>![](./images/8.1-1.png)</center>

### 8.1.3 采样策略的重要性

* **贪婪采样(greedy sampling)**：贪婪抽取，从模型预测的下一个字符的概率分布中，抽取概率最大的
* **随机采样(stochastic sampling)**：随机抽取，从模型预测的下一个字符的概率分布中，随机抽取
* 贪婪抽取最具有更加可预测的结构，随机抽取最更有创造性的机构，控制偏向哪边的参数 设定为temperature，取汁0～1，
`temperature=0 #贪婪抽取`
`temperature=1 #随机抽取`

[对于不同的 softmax 温度，对概率分布进行重新加权x](./images/book8_1-1.py)

### 8.1.4 实现字符级的LSTM文本生成
[实现字符级的LSTM文本生成](./book8_1-2.py)

温度temperature越高，越随机

该模型所做的只是从一个统计模型中对数据进行采样，这个模型是关于**字符先后顺序**的模型；信息的**内容**与信息**编码的统计结构**是有区别的

### 8.1.5 小结

* 我们可以生成离散的序列数据，其方法是:给定前面的标记，训练一个模型来预测接下来的一个或多个标记。
* 对于文本来说，这种模型叫作**语言模型**。它可以是单词级的，也可以是字符级的。
* 对下一个标记进行采样，需要在坚持模型的判断与引入随机性之间寻找平衡。
* 处理这个问题的一种方法是使用 softmax 温度。一定要尝试多种不同的温度，以找到合适的那一个。

## 8.2 DeepDream
### 8.2.1 用Keras实现DeepDream
[用Keras实现DeepDream](./book8_2-1.py)
### 8.2.2 小结

* DeepDream 的过程是反向运行一个卷积神经网络，基于网络学到的表示来生成输入。
* 得到的结果是很有趣的，有些类似于通过迷幻剂扰乱视觉皮层而诱发的视觉伪影。
* 注意，这个过程并不局限于图像模型，甚至并不局限于卷积神经网络。它可以应用于语音音乐等更多内容。

## 8.3 神经风格迁移
**神经风格迁移**是指：将**参考图像的风格**应用于**目标图像**，同时保留目标图像的内容
![](./images/8.3-1.png)

实现风格迁移背后的**关键概念**与所有深度学习算法的**核心思想**是一样的：**定义一个损失函数来指定想要实现的目标，然后将这个损失最小化**

```
loss = 
distance(
	style(reference_image)-style(generated_image)	# 参考图片的风格-生成图片的风格 = 风格损失，生成图像的风格尽可能接近参考图像的风格
) +
distance(
	content(originnal_image)-content(generated_image) 	# 原始图片的内容-生成图片的内容 = 内容损失,生成图像的内容尽可能接近原始图像的内容
) 
# 将loss最小化，则目标图片的风格就回接近与参考图片的风格，目标图片的内容就回接近与原始图片的内容，
# distance 是一个范数函数，比如 L2 范数
```
Gatys 等人发现了一个很重要的观察结果，就是**深度卷积神经网络**能够从数学上定义 **style** 和 **content** 两个函数

### 8.3.1 内容损失
网络更靠底部的层激活包含关于图像的**局部**信息，而更靠近顶部的层则包含更加**全局**、更加**抽象**的信息，因此：

👻：顶部层---内容，底部层不对应风格，而是层的内部相互关系---纹理\风格

风格损失：两个激活之间的L2范数，一个激活是预训练的卷积神经网络靠**顶部**某层在**原始图像**上得到的激活，另一个激活是**同一层**在**生成图像**上得到的激活

该层的所有特征的激活

```
loss_content=distance(content_originnal-content_generated)
```

### 8.3.2 风格损失
层的内部关系---风格\纹理

为了保证了在**风格参考**图像与**生成图像**之间，在**不同空间尺度**中，找到的**纹理**看起来都很**相似**

必须要实现：**风格参考**图像与**生成图像**之间，在**不同的层激活内**，要保存**相似**的**内部相互关系**

👻：不同空间尺寸---不同层激活；纹理---内部相互关系(内积)

### 8.3.3 用Keras实现神经风格迁移

损失 = 内容损失+风格损失：

* 在**原始内容图像**和**生成图像**之间保持相似的**较高层**激活---内容
* 在**较低层**和**较高层**的激活中保持类似的**相互关系**(correlation)---风格\纹理，且是不同空间尺度中

神经风格迁移的一遍过程如下：

1. **创建一个网络**，它能够同时计算三个图像的VGG19的层激活，原始图像、参考图像、生成图像
2. 使用这三张图像上计算的层激活来**定义**之前所述的**损失函数**，为了实现风格迁移，需要将这个损失函数最小化
3. **设置梯度下降过程**来将这个损失函数最小化。

[具体实现](./book8_3-1.py)
![](./images/8.3-2.png)

其实该方法只是纹理迁移，无法实现比较抽象的迁移

风格迁移算法非常慢，实现快速风格迁移的方法是，对一张固定的风格参考图片，生成足够多的输入-输出训练样例，然后训练一个简单的卷积神经网络来学习这个风格变换

👻：获取足够多的微信马赛克图片，输出-输入阳历，是否能实现去马效果

### 8.3.4 小结

* 风格迁移是指创建一张新图像，保留目标图像的内容的同时还抓住了参考图像的风格
* 内容可以被卷积神经网络更靠顶部的层激活所捕捉到
* 风格可以被卷积神经网络不同层激活的内部相互关系所捕捉到
* 因此，深度学习可以将风格迁移表述为一个最优化过程，并用到了一个用预训练卷积神经网络所定义的损失
* 从这个基本想法出发，可以有许多变体和改进

## 8.4 用变分自编码器生成图像
### 8.4.1 从图像的潜在空间中采样
### 8.4.2 图像编辑的概念向量
### 8.4.3 变分自编码器
### 8.4.4 小结

## 8.5 生成式对抗网络简介
### 8.5.1 GAN的简要实现流程
### 8.5.2 大量技巧
### 8.5.3 生成器
### 8.5.4 判别器
### 8.5.5 对抗网络
### 8.5.6 如何训练DCGAN
### 8.5.7 小结

## 本章总结