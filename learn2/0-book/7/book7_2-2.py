#coding=utf-8

# çŒ«ğŸ± ç‹—ğŸ¶ å›¾ç‰‡åˆ†ç±»å™¨ï¼ŒåŸºç¡€æ¨¡ï¼Œä¸book5.2.pyå¯¹æ¯”ï¼Œä½¿ç”¨å‡½æ•°æ˜¯apiï¼Œä½¿ç”¨å›è°ƒå‡½æ•°

import os, shutil
import keras
from keras import layers
from keras import models
from keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
import tensorflow as tf
from keras import Input

config = tf.ConfigProto(log_device_placement=False)    # æ˜¯å¦æ‰“å°è®¾å¤‡åˆ†é…æ—¥å¿—
config.gpu_options.per_process_gpu_memory_fraction=0.5 # è®¾ç½®æ¯ä¸ªgpuåº”è¯¥æ‹¿å‡ºå¤šå°‘å®¹é‡ç»™è¿›ç¨‹ä½¿ç”¨
config.operation_timeout_in_ms=15000   # terminate on long hangs
sess = tf.InteractiveSession("", config=config)

original_dataset_dir='../5/data/dogs-vs-cats/train'   #åŸå§‹æ•°æ®é›†è§£å‹ç›®å½•çš„è·¯å¾„
base_dir='../5/data/cats_and_dogs_small'  #ä¿å­˜è¾ƒå°æ•°æ®é›†çš„ç›®å½•
#os.mkdir(base_dir)
train_dir=os.path.join(base_dir, 'train')   #è®­ç»ƒ
validation_dir=os.path.join(base_dir, 'validation') #æ ¡éªŒ
test_dir=os.path.join(base_dir, 'test') #æµ‹è¯•
train_cats_dir=os.path.join(train_dir, 'cats')
train_dogs_dir=os.path.join(train_dir, 'dogs')
validation_cats_dir=os.path.join(validation_dir, 'cats')
validation_dogs_dir=os.path.join(validation_dir, 'dogs')
test_cats_dir=os.path.join(test_dir, 'cats')
test_dogs_dir=os.path.join(test_dir, 'dogs')

# å‡†å¤‡æ•°æ®
def copyData():
	#å°†å‰1000å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°train_cats_dir
	fnames=['cat.{}.jpg'.format(i) for i in range(1000)]  #{}æ˜¯å ä½ç¬¦ï¼Œå¡«å†™format(i)ä¸­çš„i å¾—åˆ°cat.0.jpg,cat.1.jpg...
	for fname in fnames:
		src = os.path.join(original_dataset_dir, fname)
		dst = os.path.join(train_cats_dir, fname)
		shutil.copyfile(src, dst)
	#å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°validation_cats_dir
	fnames=['cat.{}.jpg'.format(i) for i in range(1000,1500)]
	for fname in fnames:
		src = os.path.join(original_dataset_dir, fname)
		dst = os.path.join(validation_cats_dir, fname)
		shutil.copyfile(src, dst)
	#å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°test_cats_dir
	fnames=['cat.{}.jpg'.format(i) for i in range(1500,2000)]
	for fname in fnames:
		src = os.path.join(original_dataset_dir, fname)
		dst = os.path.join(test_cats_dir, fname)
		shutil.copyfile(src, dst)

	fnames=['dog.{}.jpg'.format(i) for i in range(1000)]
	for fname in fnames:
		src = os.path.join(original_dataset_dir, fname)
		dst = os.path.join(train_dogs_dir, fname)
		shutil.copyfile(src, dst)
	#å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°validation_cats_dir
	fnames=['dog.{}.jpg'.format(i) for i in range(1000,1500)]
	for fname in fnames:
		src = os.path.join(original_dataset_dir, fname)
		dst = os.path.join(validation_dogs_dir, fname)
		shutil.copyfile(src, dst)
	#å°†500å¼ çŒ«çš„å›¾ç‰‡å¤åˆ¶åˆ°test_cats_dir
	fnames=['dog.{}.jpg'.format(i) for i in range(1500,2000)]
	for fname in fnames:
		src = os.path.join(original_dataset_dir, fname)
		dst = os.path.join(test_dogs_dir, fname)
		shutil.copyfile(src, dst)

#copyData()

def getModel():
	#æ­å»ºæ¨¡å‹
	model=models.Sequential()
	model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))
	model.add(layers.MaxPooling2D(2,2))
	model.add(layers.Conv2D(64, (3,3), activation='relu' ))
	model.add(layers.MaxPooling2D(2,2))
	model.add(layers.Conv2D(128, (3,3), activation='relu' ))
	model.add(layers.MaxPooling2D(2,2))
	model.add(layers.Conv2D(128, (3,3), activation='relu' ))
	model.add(layers.MaxPooling2D(2,2))
	model.add(layers.Flatten())
	model.add(layers.Dense(512, activation='relu'))
	model.add(layers.Dense(1, activation='sigmoid'))
	model.summary()
	# ç¼–è¯‘æ¨¡å‹
	model.compile(loss='binary_crossentropy',
		    optimizer=optimizers.RMSprop(lr=1e-4),
		    metrics=['acc']
		)
	return model

def getModel_api():
	x = Input(shape=(150,150,3))
	c1 = layers.Conv2D(32, (3,3), activation='relu')(x)
	c1 = layers.MaxPooling2D(2,2)(c1)
	c2 = layers.Conv2D(64, (3,3), activation='relu')(c1)
	c2 = layers.MaxPooling2D(2,2)(c2)
	c3 = layers.Conv2D(128, (3,3), activation='relu')(c2)
	c3 = layers.MaxPooling2D(2,2)(c3)
	c4 = layers.Conv2D(128, (3,3), activation='relu')(c3)
	c4 = layers.MaxPooling2D(2,2)(c4)

	f1 = layers.Flatten()(c4)
	d1 = layers.Dense(512, activation='relu')(f1)
	d2 = layers.Dense(1, activation='sigmoid')(d1)

	model = models.Model(x, d2)
	model.compile(loss='binary_crossentropy',
		    optimizer=optimizers.RMSprop(lr=1e-4),
		    metrics=['acc']
		)
	#model.summary()
	return model


def getData():
	#æ•°æ®é¢„å¤„ç†
	train_datagen=ImageDataGenerator(rescale=1./255)    #è®¾ç½®æ”¾ç¼©æ¯”ä¾‹
	test_datagen=ImageDataGenerator(rescale=1./255)

	train_generator=train_datagen.flow_from_directory(  #æ„å»ºpythonç”Ÿæˆå™¨,æ˜¯ä¸€ä¸ªç±»ä¼¼è¿­ä»£å™¨çš„å¯¹è±¡,ä»ç›®å½•ä¸­è¯»å–å›¾åƒæ•°æ®å¹¶é¢„å¤„ç†
		train_dir,  #ç›®æ ‡ç›®å½•
		target_size=(150, 150), #å°†æ‰€æœ‰å›¾ç‰‡çš„å¤§å°è°ƒæ•´ä¸º150*150
		batch_size=20,          #ç”Ÿæˆå™¨æ¯æ‰¹æ¬¡æ ·æœ¬æ•°é‡
		class_mode='binary'     #å› ä¸ºä½¿ç”¨äº†binary_crossentropyæŸå¤±ï¼Œæ‰€ä»¥éœ€è¦ç”¨äºŒè¿›åˆ¶æ ‡ç­¾
		)
	validation_generator=test_datagen.flow_from_directory(
		validation_dir,
		target_size=(150, 150),
		batch_size=20,
		class_mode='binary'
		)
	return train_generator, validation_generator

def getCallbackslist():
	callbacks_list = [
		keras.callbacks.ModelCheckpoint(	# æ£€æŸ¥ç‚¹å›è°ƒå‡½æ•°
			filepath='my_model_7_2-1.h5',	# ä¿å­˜æ–‡ä»¶å
			monitor='val_loss',		# å¦‚æœval_lossæ²¡æœ‰æ”¹å–„ï¼Œå°±ä¸è¦†ç›–ï¼Œ
			save_best_only=True,		# ä¿å­˜æœ€ä½³è®­ç»ƒç»“æœ
		),
		keras.callbacks.ReduceLROnPlateau(
			monitor='val_loss',		# ç›‘æ§æŒ‡æ ‡ï¼šval_loss
			patience=10,			# å‡ºå‘æ¡ä»¶ï¼šç›‘æ§æŒ‡æ ‡åœ¨10è½®å†…æ²¡æœ‰æ”¹è¿›
			factor=0.1,				# å‡ºå‘äº‹ä»¶ï¼šå­¦ä¹ ç‡å˜ä¸ºåŸæ¥çš„0.1å€
		)
	]

	return callbacks_list

def validModel(train_generator, validation_generator):
	sm=models.load_model('my_model_7_2-1.h5')
	v_loss,v_acc=sm.evaluate_generator(validation_generator, steps=50)
	print(v_loss, v_acc)


def run(model, train_generator, validation_generator):
	callbacks_list = getCallbackslist()
	history=model.fit_generator(
		train_generator,
		steps_per_epoch=100,    # æ¯ä¸€è½®æŠ½å–å¤šå°‘æ‰¹æ¬¡çš„ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®
		epochs=40,
		validation_data=validation_generator,
		validation_steps=50,                 # ä»éªŒè¯é›†ä¸­æŠ½å–å¤šå°‘ä¸ªæ‰¹æ¬¡ç”¨äºè¯„ä¼°
		callbacks=callbacks_list  # ä¼ å…¥å›è°ƒå‡½æ•°åˆ—è¡¨
		)
	#model.save('cats_and_dogs_small_7_2-1.h5')  #ä¿å­˜æ¨¡å‹
	return history

def show2(t_loss,t_acc,v_loss,v_acc):
	epochs=range(1, len(t_loss)+1)
	plt.figure(figsize=(10,5))
	plt.subplot(1,2,1)
	plt.plot(epochs, t_loss, 'b', label='t_loss')
	plt.plot(epochs, v_loss, 'r', label='v_loss')
	plt.ylim([0,1])
	plt.title('loss')
	plt.legend()
	plt.subplot(1,2,2)
	plt.plot(epochs, t_acc, 'b', label='t_acc')
	plt.plot(epochs, v_acc, 'r', label='v_acc')
	plt.ylim([0,1])
	plt.title('acc')
	plt.legend()
	plt.show()

if __name__=='__main__':
	train_generator, validation_generator = getData()
	#model=getModel()
	model=getModel_api()
	history=run(model, train_generator, validation_generator)
	validModel(train_generator, validation_generator)
	t_loss=history.history['loss']
	t_acc=history.history['acc']
	v_loss=history.history['val_loss']
	v_acc=history.history['val_acc']

	show2(t_loss,t_acc,v_loss,v_acc)
	'''
	validModel(train_generator, validation_generator)
	'''
